# This is 100% generated by ChatGPT

import os
import subprocess
import tempfile
import shutil
import requests
import json

USERNAME = "StochasticBiology"  # Replace with the GitHub username
TOKEN = None  # Optional GitHub token

headers = {
    "Accept": "application/vnd.github.v3+json",
    "Authorization": f"token {TOKEN}" if TOKEN else None
}

def get_repos(user):
    url = f"https://api.github.com/users/{user}/repos?per_page=100&type=public"
    repos = []
    while url:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        repos.extend(response.json())
        url = response.links.get('next', {}).get('url')
    return repos

def run_cloc(repo_path):
    try:
        result = subprocess.run(
            ["cloc", "--json", repo_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            universal_newlines=True,  # replaces text=True in older versions
            check=True
        )
        data = json.loads(result.stdout)
        return data
    except subprocess.CalledProcessError as e:
        print(f"Error running cloc on {repo_path}: {e}")
        return {}

def aggregate_cloc_data(data_list):
    aggregated = {}
    for data in data_list:
        for lang, stats in data.items():
            if lang in ["header", "SUM"]:
                continue
            if lang not in aggregated:
                # Ensure all keys exist with defaults
                aggregated[lang] = {
                    "files": stats.get("files", 0),
                    "blank": stats.get("blank", 0),
                    "comment": stats.get("comment", 0),
                    "code": stats.get("code", 0)
                }
            else:
                for key in ["files", "blank", "comment", "code"]:
                    aggregated[lang][key] += stats.get(key, 0)
    return aggregated

def main():
    repos = get_repos(USERNAME)
    print(f"Found {len(repos)} public repos for user '{USERNAME}'")
    all_cloc_data = []

    with tempfile.TemporaryDirectory() as tmpdir:
        for repo in repos:
            clone_url = repo["clone_url"]
            repo_name = repo["name"]
            local_path = os.path.join(tmpdir, repo_name)
            print(f"Cloning {clone_url}...")
            try:
                subprocess.run(["git", "clone", "--depth", "1", clone_url, local_path], check=True, stdout=subprocess.DEVNULL)
                cloc_data = run_cloc(local_path)
                all_cloc_data.append(cloc_data)
            except subprocess.CalledProcessError as e:
                print(f"Failed to clone {clone_url}: {e}")
                continue

    totals = aggregate_cloc_data(all_cloc_data)

    print("\nTotal Lines of Code by Language:")
    for lang, stats in sorted(totals.items(), key=lambda x: x[1]["code"], reverse=True):
        print(f"{lang}: {stats['code']} lines of code")

if __name__ == "__main__":
    main()
